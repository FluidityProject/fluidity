<?xml version="1.0" encoding="UTF-8"?>
<grammar xmlns:a="http://relaxng.org/ns/compatibility/annotations/1.0" xmlns="http://relaxng.org/ns/structure/1.0" datatypeLibrary="http://www.w3.org/2001/XMLSchema-datatypes">
  <define name="adaptivity_preprocessing">
    <optional>
      <element name="preprocessing">
        <a:documentation>Occasionally, it is desirable to apply operations or filters
to fields before using them for the purposes of adaptivity.</a:documentation>
        <element name="helmholtz_smoother">
          <a:documentation>Invert a helmholtz operator to smooth out the field
before using it to adapt. This can help with noisy
fields.</a:documentation>
          <element name="smoothing_length_scale">
            <ref name="real_dim_symmetric_tensor"/>
          </element>
          <element name="solver">
            <ref name="linear_solver_options_sym"/>
          </element>
        </element>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_prognostic_scalar_field">
    <optional>
      <element name="adaptivity_options">
        <choice>
          <element name="absolute_measure">
            <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
            <element name="scalar_field">
              <attribute name="rank">
                <value>0</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_scalar_field_no_adapt"/>
              </element>
            </element>
            <optional>
              <element name="p_norm">
                <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="relative_measure">
            <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
            <element name="scalar_field">
              <attribute name="rank">
                <value>0</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_scalar_field_no_adapt"/>
              </element>
            </element>
            <element name="tolerance">
              <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
              <ref name="real"/>
            </element>
          </element>
          <element name="anisotropic_zienkiewicz_zhu">
            <a:documentation>Adapt using the anisotropic strategy of 
Formaggia, Perotto, Micheletti.
Rather than taking two derivatives
and deriving the anisotropic information,
this approach computes an anisotropic Zienkiewicz-Zhu
error estimator for each element. The approach then
optimises the element orientation and length scales
to equidistribute the estimated error.</a:documentation>
            <element name="tau">
              <a:documentation>Tau is an anisotropic estimate for the H1 seminorm of the
error. This estimator is efficient and reliable, under the
caveat that the initial mesh is sufficiently fine so as to
prevent data oscillation. (Micheletti &amp; Perotto, 2006)
Typically, tau will be ~= 6-8 * |e|_H1.</a:documentation>
              <ref name="real"/>
            </element>
          </element>
        </choice>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_scalar_field.adaptivity_options">
    <choice>
      <element name="absolute_measure">
        <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
        <element name="scalar_field">
          <attribute name="rank">
            <value>0</value>
          </attribute>
          <attribute name="name">
            <value>InterpolationErrorBound</value>
          </attribute>
          <element name="prescribed">
            <ref name="prescribed_scalar_field_no_adapt"/>
          </element>
        </element>
        <optional>
          <element name="p_norm">
            <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
            <ref name="integer"/>
          </element>
        </optional>
      </element>
      <element name="relative_measure">
        <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
        <element name="scalar_field">
          <attribute name="rank">
            <value>0</value>
          </attribute>
          <attribute name="name">
            <value>InterpolationErrorBound</value>
          </attribute>
          <element name="prescribed">
            <ref name="prescribed_scalar_field_no_adapt"/>
          </element>
        </element>
        <element name="tolerance">
          <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
          <ref name="real"/>
        </element>
      </element>
      <element name="anisotropic_zienkiewicz_zhu">
        <a:documentation>Adapt using the anisotropic strategy of 
Formaggia, Perotto, Micheletti.
Rather than taking two derivatives
and deriving the anisotropic information,
this approach computes an anisotropic Zienkiewicz-Zhu
error estimator for each element. The approach then
optimises the element orientation and length scales
to equidistribute the estimated error.</a:documentation>
        <element name="tau">
          <a:documentation>Tau is an anisotropic estimate for the H1 seminorm of the
error. This estimator is efficient and reliable, under the
caveat that the initial mesh is sufficiently fine so as to
prevent data oscillation. (Micheletti &amp; Perotto, 2006)
Typically, tau will be ~= 6-8 * |e|_H1.</a:documentation>
          <ref name="real"/>
        </element>
      </element>
    </choice>
  </define>
  <define name="adaptivity_options_scalar_field">
    <optional>
      <element name="adaptivity_options">
        <ref name="adaptivity_options_scalar_field.adaptivity_options"/>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_prognostic_vector_field">
    <optional>
      <element name="adaptivity_options">
        <a:documentation>Adaptivity weights</a:documentation>
        <choice>
          <element name="absolute_measure">
            <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
            <element name="vector_field">
              <attribute name="rank">
                <value>1</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_vector_field_no_adapt"/>
              </element>
            </element>
            <optional>
              <element name="p_norm">
                <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="relative_measure">
            <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
            <element name="vector_field">
              <attribute name="rank">
                <value>1</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_vector_field_no_adapt"/>
              </element>
            </element>
            <element name="tolerance">
              <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
              <ref name="real_dim_vector"/>
            </element>
          </element>
        </choice>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_vector_field">
    <optional>
      <element name="adaptivity_options">
        <a:documentation>Adaptivity weights</a:documentation>
        <choice>
          <element name="absolute_measure">
            <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
            <element name="vector_field">
              <attribute name="rank">
                <value>1</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_vector_field_no_adapt"/>
              </element>
            </element>
            <optional>
              <element name="p_norm">
                <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="relative_measure">
            <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
            <element name="vector_field">
              <attribute name="rank">
                <value>1</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_vector_field_no_adapt"/>
              </element>
            </element>
            <element name="tolerance">
              <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
              <ref name="real_dim_vector"/>
            </element>
          </element>
        </choice>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_prognostic_tensor_field">
    <optional>
      <element name="adaptivity_options">
        <a:documentation>Adaptivity weights</a:documentation>
        <choice>
          <element name="absolute_measure">
            <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
            <element name="tensor_field">
              <attribute name="rank">
                <value>2</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_values_tensor_field"/>
              </element>
            </element>
            <optional>
              <element name="p_norm">
                <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="relative_measure">
            <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
            <element name="tensor_field">
              <attribute name="rank">
                <value>2</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_values_tensor_field"/>
              </element>
            </element>
            <element name="tolerance">
              <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
              <ref name="real_dim_tensor"/>
            </element>
          </element>
        </choice>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="adaptivity_options_tensor_field">
    <optional>
      <element name="adaptivity_options">
        <a:documentation>Adaptivity weights</a:documentation>
        <choice>
          <element name="absolute_measure">
            <a:documentation>When specifying absolute measure
one specifies the absolute interpolation 
error in the units of the field that is 
being adapted, e.g. you can specify
the error to be 1.3 units </a:documentation>
            <element name="tensor_field">
              <attribute name="rank">
                <value>2</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_values_tensor_field"/>
              </element>
            </element>
            <optional>
              <element name="p_norm">
                <a:documentation>By default the interpolation error controlled is the L_inf
norm. Use this option to specify an alternative L_p norm. See
Chen Sun and Zu, Mathematics of Computation, Volume 76,
Number 257, January 2007, pp. 179-204.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="relative_measure">
            <a:documentation>When specifying relative measure
one specifies the interpolation error
relative to the field that is
being adapted, e.g. you can specify
the error to be 5% (i.e. 0.05)</a:documentation>
            <element name="tensor_field">
              <attribute name="rank">
                <value>2</value>
              </attribute>
              <attribute name="name">
                <value>InterpolationErrorBound</value>
              </attribute>
              <element name="prescribed">
                <ref name="prescribed_values_tensor_field"/>
              </element>
            </element>
            <element name="tolerance">
              <a:documentation>The relative Hessian is calculated according to:

  Q = H / max{ |psi|, psi_min}

where H is the Hessian, psi is the field value and
psi_min is the tolerance. The tolerance prevents
division by zero errors.

Source: Fluidity/ICOM manual draft version 1.2</a:documentation>
              <ref name="real_dim_tensor"/>
            </element>
          </element>
        </choice>
        <ref name="adaptivity_preprocessing"/>
      </element>
    </optional>
  </define>
  <define name="hr_adaptivity">
    <element name="hr_adaptivity">
      <a:documentation>Anisotropic mesh hr-adaptivity</a:documentation>
      <ref name="hr_adaptivity_period"/>
      <optional>
        <ref name="minimum_number_of_nodes"/>
      </optional>
      <optional>
        <ref name="adaptive_timestep_at_adapt"/>
      </optional>
      <ref name="max_nodes_and_max_node_increase"/>
      <optional>
        <ref name="node_locking"/>
      </optional>
      <optional>
        <ref name="functional_tolerance"/>
      </optional>
      <ref name="gradation_options_full"/>
      <optional>
        <ref name="metric_advection"/>
      </optional>
      <optional>
        <ref name="geometric_constraints"/>
      </optional>
      <optional>
        <ref name="bounding_box_factor"/>
      </optional>
      <optional>
        <ref name="goal_based_adaptivity"/>
      </optional>
      <ref name="min_and_max_edge_and_reference_mesh_bound_and_aspect_ratio_bound"/>
      <optional>
        <ref name="adapt_at_first_timestep"/>
      </optional>
      <optional>
        <ref name="preserve_mesh_regions"/>
      </optional>
      <optional>
        <ref name="vertically_structured_adaptivity"/>
      </optional>
      <optional>
        <ref name="zoltan_options"/>
      </optional>
      <optional>
        <ref name="adaptivity_library"/>
      </optional>
      <optional>
        <ref name="adapt_iterations"/>
      </optional>
      <optional>
        <ref name="hr_adaptivity_debug"/>
      </optional>
    </element>
  </define>
  <define name="hr_adaptivity_period">
    <choice>
      <element name="period">
        <a:documentation>Time interval (in simulation time) when mesh adaptivity performed.

Usually set to 10-20 times the timestep.</a:documentation>
        <ref name="real"/>
      </element>
      <element name="period_in_timesteps">
        <a:documentation>Adapt period in timesteps.</a:documentation>
        <ref name="integer"/>
      </element>
    </choice>
    <optional>
      <element name="cpu_period">
        <a:documentation>Time interval (in cpu time) when mesh adaptivity performed
Manual suggests disabling this option.</a:documentation>
        <ref name="real"/>
      </element>
    </optional>
  </define>
  <define name="minimum_number_of_nodes">
    <element name="minimum_number_of_nodes">
      <a:documentation>The minimum number of nodes this simulation may use.
In parallel, by default, this is the global minimum number of nodes.

If the mesh adaptivity algorithm wants to place fewer nodes
than this, the desired mesh is refined everywhere in space
until it will exceed this limit. This option should generally
only be used if a specified node count is being targetted.
Default value: 0</a:documentation>
      <optional>
        <element name="per_process">
          <a:documentation>Define minimum_number_of_nodes to be the minimum number of
nodes per process (rather than the global minimum number of
nodes).</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
      <ref name="integer"/>
    </element>
  </define>
  <define name="adaptive_timestep_at_adapt">
    <element name="adaptive_timestep_at_adapt">
      <a:documentation>Use the minimum timestep at an adapt and ramp back up the maximum</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="max_nodes_and_max_node_increase">
    <element name="maximum_number_of_nodes">
      <a:documentation>The maximum number of nodes this simulation may use.
In parallel, by default, this is the global maximum number of nodes.

If the mesh adaptivity algorithm wants to place more
nodes than this, the desired mesh is coarsened
everywhere in space until it will fit within this limit.
In general, the error tolerances should be set so that
this is never reached; it should only be a safety catch.
A typical value is 100000.

When using vertically_structured_adaptivity this indicates the 
maximum number of nodes in the horizontal mesh, i.e. the number
of nodes in the full mesh will be much bigger and depends on the 
number of layers specified, or if using inhomogenous_vertical_resolution
on the resolution produced by the vertical adaptivity step.</a:documentation>
      <optional>
        <element name="per_process">
          <a:documentation>Define maximum_number_of_nodes to be the maximum number of
nodes per process (rather than the global maximum number of
nodes).</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
      <ref name="integer"/>
    </element>
    <optional>
      <element name="max_node_increase">
        <a:documentation>The maximum ratio by which the number of nodes is allowed to
increase in an adapt. e.g., a value of 1.1 indicates that the
number of nodes may be increased by at most 10%.</a:documentation>
        <ref name="real"/>
      </element>
    </optional>
  </define>
  <define name="node_locking">
    <element name="node_locking">
      <a:documentation>Enable to lock nodes in the mesh.</a:documentation>
      <element name="python">
        <a:documentation>Python function defining nodes to lock. Return 0 for free
nodes, and non-zero for locked nodes. Functions should be
of the form:

 def val(x, t):
    # Function code
    return # Return value

The return value must be an integer.</a:documentation>
        <ref name="python_code"/>
      </element>
      <ref name="comment"/>
    </element>
  </define>
  <define name="functional_tolerance">
    <element name="functional_tolerance">
      <a:documentation>Specifies the minimum element functional value for which elements
are considered for adaptivity. For the Pain et al 2001 functional,
ideal tetrahdera have a functional value of 0.0. A functional value
of 0.5 corresponds to a tetrehedron with: unit edge lengths and
and in-sphere radius of 0.3, or alternatively unit in-sphere radius,
five edges of unit length and a single edge of length 2
(all measured in metric space).

The minimum permitted value is 0.15 - the value supplied to
libadaptivity is max(abs(user value), 0.15).

Default value if not specified: 0.15</a:documentation>
      <ref name="real"/>
    </element>
  </define>
  <define name="metric_advection">
    <element name="metric_advection">
      <a:documentation>Metric advection algorithm.
By advecting the metric with the flow velocity,
we can push mesh resolution ahead of the flow dynamics,
rather than always lagging behind.</a:documentation>
      <element name="spatial_discretisation">
        <a:documentation>Spatial discretisation options</a:documentation>
        <element name="control_volumes">
          <ref name="standard_control_volume_options_excluding_cfl"/>
        </element>
        <element name="conservative_advection">
          <a:documentation>Conservative discretisation of field advection equation
 TBETA=1. -- conservative (divergence form)
 TBETA=0. -- non-conservative
 0. &lt; TBETA &lt; 1.</a:documentation>
          <ref name="real"/>
        </element>
      </element>
      <element name="temporal_discretisation">
        <element name="theta">
          <a:documentation>Implicit/explicit control (TTHETA)
 =0.  -- explicit
 =0.5 -- Crank-Nicolson
 =1.  -- implicit</a:documentation>
          <ref name="real"/>
        </element>
        <choice>
          <element name="maximum_courant_number_per_subcycle">
            <a:documentation>Use subcycling to advect the metric.

Specify the maximum courant number per subcycle.</a:documentation>
            <ref name="real"/>
            <ref name="field_based_cfl_number_options"/>
          </element>
          <element name="number_advection_subcycles">
            <a:documentation>Use subcycling to advect the metric.

Specify the number of subcycles.</a:documentation>
            <ref name="integer"/>
          </element>
        </choice>
        <optional>
          <element name="scale_advection_time">
            <a:documentation>Scale the time period over which the metric is
advected by this factor.

Default is 1.1</a:documentation>
            <ref name="real"/>
          </element>
        </optional>
        <element name="control_volumes">
          <a:documentation>Temporal discretisation options for the control volume discretisation</a:documentation>
          <optional>
            <element name="number_advection_iterations">
              <a:documentation>Number of iterations within an advection solve.
This increases the accuracy of the face values and ensures that
the pivoted solution is cancelled out.
Defaults to 1 if unselected.</a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <optional>
            <element name="limit_theta">
              <a:documentation>If not active then the theta specified above will be used.
Otherwise use variable limited theta on individual faces.</a:documentation>
              <empty/>
            </element>
          </optional>
          <optional>
            <element name="pivot_theta">
              <a:documentation>Time discretisation of upwind discretisation off which the
higher order solution is pivotted.
 - pivot_theta = 1 - implicit pivot (default if not set and 
                     best choice if not intentionally modifying
                     scheme to be explicit)
 - pivot_theta = 0 - explicit pivot</a:documentation>
                  <ref name="real"/>
                </element>
              </optional>
            </element>
          </element>
          <choice>
            <element name="solver">
              <a:documentation>Solver</a:documentation>
              <ref name="linear_solver_options_asym_scalar"/>
            </element>
            <element name="explicit">
              <a:documentation>Assume this field is being solved explicitly and skip the solver.

Assumes lhs matrix only has diagonal lumped mass
and divides the rhs by this.</a:documentation>
          <empty/>
        </element>
      </choice>
      <optional>
        <ref name="metric_advection_velocity_name"/>
      </optional>
      <optional>
        <ref name="porosity_include"/>
      </optional>
      <element name="output">
        <a:documentation>Debugging output options</a:documentation>
        <optional>
          <element name="output_subcycle_vtus">
            <a:documentation>Output vtus of the advected metric and edge lengths at every subcycle</a:documentation>
            <empty/>
          </element>
        </optional>
        <optional>
          <element name="output_final_vtus">
            <a:documentation>Output vtus of the final metric merged over all the subcycles</a:documentation>
            <empty/>
          </element>
        </optional>
      </element>
    </element>
  </define>
  <define name="metric_advection_velocity_name">
    <element name="advecting_velocity_field_name">
      <a:documentation>The name of the field used to advect the metric
that must exist in the first material_phase.
If not given then the NonlinearVelocity is used.</a:documentation>
      <data type="string"/>
    </element>
  </define>
  <define name="geometric_constraints">
    <element name="geometric_constraints">
      <a:documentation>Apply geometric constraints to the metric formation.

As specified in (Pain, 2001), the mesh adaptivity
scheme attempts to formulate an appropriate edge length
for each direction at each point in space, independent
of problem, PDE or domain.

This option instructs the error metric formation
code to inspect the boundaries of the domain
and to bound the edge lengths requested appropriately.
This procedure stops the metric from asking for edge lengths
that are inappropriately large in comparison to the
resolution required to preserve the geometric accuracy
of the boundaries.

If you get 'knife elements' near domain boundaries,
turn this on.</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="bounding_box_factor">
    <element name="bounding_box_factor">
      <a:documentation>Bounding box factor.

If the length scales specified by the metric are
unrealistically large, the mesh optimisation
algorithm can get confused. An example
would be specifying a length scale in a direction to be an
order of magnitude greater than the width
of the domain.

In order to fix this, the edge lengths requested
are bounded by the bounding box of the domain
(the smallest cuboid that contains the domain).
However, it was found that bounding by the bounding
box impairs the generation of anisotropic elements
in the mesh optimisation algorithm.

This option is multiplied by the bounding box of the domain
before it bounds the metric formed from other
considerations. By default, it is set to 2.0.</a:documentation>
      <ref name="real"/>
    </element>
  </define>
  <define name="goal_based_adaptivity">
    <optional>
      <element name="goal_based_adaptivity">
        <a:documentation>Goal-based adaptivity. 

With this option,
rather than taking the user-specified interpolation
error bounds as the weights to form the error metric
from the Hessians of the solution fields,
the interpolation weight is computed to optimally
represent the value of some specified functional
of state. In other words, the mesh is optimised
for the representation of a particular goal.

This is currently experimental. Activating
this option induces the code to ignore
any error bounds associated with the fields
specified under a material_phase.

For more information on this scheme,
see (Venditti &amp; Darmofal, 2003), or
(Power et. al, 2006).

Coding your own goal is also possible
but currently undocumented. See
error_measures/Goals.F90
for examples.</a:documentation>
        <choice>
          <element name="enstrophy_goal">
            <a:documentation>Optimise for the representation of
enstrophy,
  0.5 * int( |curl(velocity)|**2 ) dV.</a:documentation>
            <attribute name="subroutine">
              <value>goal_enstrophy</value>
            </attribute>
            <attribute name="dependencies">
              <value>Velocity%1 Velocity%2 Velocity%3</value>
            </attribute>
          </element>
          <element name="temperature_gradient_goal">
            <a:documentation>Optimise for the representation of
gradients of temperature,
  int(|grad(temperature)|**2) dV.</a:documentation>
            <attribute name="subroutine">
              <value>goal_temp</value>
            </attribute>
            <attribute name="dependencies">
              <value>Temperature</value>
            </attribute>
          </element>
          <element name="les_goal">
            <a:documentation>Optimise for the contribution of the standard
Smagorinsky LES tensor.

In effect, this goal minimises
the contribution of the sub-filter scale
model -- it applies mesh resolution where
the sub-grid scale model has an effect.

int( transpose(grad(u)) . kappa . grad(u) ) dV,
with u ranging over the components of (nonlinear)
velocity and kappa the LES tensor.</a:documentation>
            <attribute name="subroutine">
              <value>goal_les_velocity</value>
            </attribute>
            <attribute name="dependencies">
              <value>NonlinearVelocity%1 NonlinearVelocity%2 NonlinearVelocity%3</value>
            </attribute>
            <optional>
              <element name="nonlinear_iterations">
                <a:documentation>The number of nonlinear iterations to perform when
forming the metric with this goal.

Because the LES tensor explicitly depends on mesh sizing,
we can form a metric and feed this back into the goal,
using the proposed mesh sizing instead of the current mesh.
This allows us to simulate adapts without actually incurring
the cost of adaptation, for the purposes of converging the metric.
The default value is 3.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
          <element name="higher_order_les_goal">
            <a:documentation>Optimise for the contribution of the new 4th-order
LES tensor.

In effect, this goal minimises
the contribution of the sub-filter scale
model -- it applies mesh resolution where
the sub-grid scale model has an effect.

int( transpose(grad(u))   . kappa . grad(u) ) dV -
int( transpose(grad_h(u)) . kappa . grad_h(u) ) dV

with u ranging over the components of (nonlinear)
velocity, kappa the LES tensor,
grad(.) differentiation of basis functions and
grad_h(.) the Galerkin projection of the first derivative.</a:documentation>
            <attribute name="subroutine">
              <value>goal_les_velocity_4th</value>
            </attribute>
            <attribute name="dependencies">
              <value>NonlinearVelocity%1 NonlinearVelocity%2 NonlinearVelocity%3</value>
            </attribute>
            <optional>
              <element name="nonlinear_iterations">
                <a:documentation>The number of nonlinear iterations to perform when
forming the metric with this goal.

Because the LES tensor explicitly depends on mesh sizing,
we can form a metric and feed this back into the goal,
using the proposed mesh sizing instead of the current mesh.
This allows us to simulate adapts without actually incurring
the cost of adaptation, for the purposes of converging the metric.
The default value is 3.</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
          </element>
        </choice>
        <choice>
          <element name="relative_tolerance">
            <a:documentation>The tolerance of the goal specifies the acceptable
error in the quantity computed. The adaptation scheme
attempts to adapt the mesh to ensure that the
goal computed from the primitive solution is 
within the tolerance specified here.

A relative tolerance specifies that the acceptable error
in the goal is some fraction of the value as computed
from the primitive solution. It is generally 
the easiest to use. This is a unitless percentage.</a:documentation>
            <ref name="real"/>
          </element>
          <element name="absolute_tolerance">
            <a:documentation>The tolerance of the goal specifies the acceptable
error in the quantity computed. The adaptation scheme
attempts to adapt the mesh to ensure that the
goal computed from the primitive solution is 
within the tolerance specified here.

An absolute tolerance specifies the acceptable error
in the goal, in the units of the goal itself.</a:documentation>
            <ref name="real"/>
          </element>
        </choice>
      </element>
    </optional>
  </define>
  <define name="min_and_max_edge_and_reference_mesh_bound_and_aspect_ratio_bound">
    <element name="tensor_field">
      <a:documentation>Mesh size constraints: the minimum edge length bound.</a:documentation>
      <attribute name="name">
        <value>MinimumEdgeLengths</value>
      </attribute>
      <element name="anisotropic_symmetric">
        <ref name="input_choice_real_dim_symmetric_tensor"/>
      </element>
    </element>
    <element name="tensor_field">
      <a:documentation>Mesh size constraints: the maximum edge length bound.</a:documentation>
      <attribute name="name">
        <value>MaximumEdgeLengths</value>
      </attribute>
      <element name="anisotropic_symmetric">
        <ref name="input_choice_real_dim_symmetric_tensor"/>
      </element>
    </element>
    <zeroOrMore>
      <element name="reference_mesh">
        <a:documentation>Supply a reference mesh with which to bound the metric</a:documentation>
        <attribute name="name">
          <data type="string"/>
        </attribute>
        <attribute name="mesh_name">
          <data type="string"/>
        </attribute>
        <choice>
          <element name="minimum">
            <a:documentation>Use this reference mesh as a bound on the minimum edge
length of the metric</a:documentation>
            <ref name="comment"/>
          </element>
          <element name="maximum">
            <a:documentation>Use this reference mesh as a bound on the maximum edge
length of the metric</a:documentation>
            <ref name="comment"/>
          </element>
        </choice>
        <ref name="comment"/>
      </element>
    </zeroOrMore>
    <optional>
      <element name="aspect_ratio_bound">
        <a:documentation>Maximum aspect ratio in the adapted mesh.</a:documentation>
        <ref name="real"/>
      </element>
    </optional>
  </define>
  <define name="adapt_at_first_timestep">
    <element name="adapt_at_first_timestep">
      <a:documentation>Adapt at first timestep</a:documentation>
      <element name="number_of_adapts">
        <a:documentation>Number of adapts done after initialisation but
before the actual simulation starts</a:documentation>
        <ref name="integer"/>
      </element>
      <optional>
        <element name="output_adapted_mesh">
          <a:documentation>Write out the first timestep adapted mesh.
This is useful when needing to re-run simulations
without waiting for the first timestep adapt</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
    </element>
  </define>
  <define name="preserve_mesh_regions">
    <element name="preserve_mesh_regions">
      <a:documentation>Enable this option to preserve any regions in your
mesh (i.e. those specified by region_ids).
Also, any prescribed fields using region_ids will be
reinitialised using them on the new mesh.

Therefore this is a required option if you want your
prescribed region_id fields to survive adapts!
Obviously this does not apply to initial conditions
set using region_ids.</a:documentation>
      <ref name="comment"/>
    </element>
  </define>
  <define name="vertically_structured_adaptivity">
    <element name="vertically_structured_adaptivity">
      <a:documentation>Vertically structured adaptivity.

The mesh will be unstructured in the horizontal, but columnar
in the vertical.
To enable this, your meshes must be derived by extrusion
from a lower-dimensional horizontal mesh.
This will give a columnar, layered mesh.</a:documentation>
      <optional>
        <element name="inhomogenous_vertical_resolution">
          <a:documentation>If this is enabled, the resolution along each column
will be computed from the error metric.
This will give a columnar mesh, but not a layered one.</a:documentation>
          <optional>
            <element name="adapt_in_vertical_only">
              <a:documentation>Ignore the horizontal adapt, and *only* adapt in the vertical</a:documentation>
              <empty/>
            </element>
          </optional>
        </element>
      </optional>
      <optional>
        <element name="split_gradation">
          <a:documentation>Apply a separate step of horizontal (and vertical, if using inhomogeneous_vertical_resolution)
gradation to the horizontal (and vertical) metric.
This replaces is the gradation applied to the full metric and uses the gradation
algorithm specified above.</a:documentation>
          <empty/>
        </element>
      </optional>
      <choice>
        <element name="vertically_align_metric">
          <a:documentation>Remove components from each field's metric that aren't aligned either horizontally
or vertically.  This can help prevent the horizontal metric from becoming
contaminated by parts of the vertical metric.

NOTE: Vertical is defined using the GravityDirection field.  This is unlike some other
parts of the vertically_structured_adaptivity and extrusion routines where vertical is defined as the
last dimension.</a:documentation>
          <empty/>
        </element>
        <element name="use_full_metric">
          <a:documentation>When separating the horizontal metric from the vertical use the full metric.  This
can lead to more constrained horizontal resolution due to leakage between the vertical
and horizontal components.</a:documentation>
          <empty/>
        </element>
      </choice>
      <optional>
        <element name="include_bottom_metric">
          <a:documentation>When constructing the horizontal metric incorporate the components of the 
full metric tangential to the bottom boundary.  For example, this is useful 
when horizontal contours of a field intersect the bathymetry and this information
is not automatically incorporated into the horizontal metric leading to
the contact point being underresolved.

Depends on /geometry/ocean_boundaries.</a:documentation>
          <empty/>
        </element>
      </optional>
    </element>
  </define>
  <define name="zoltan_options">
    <element name="zoltan_options">
      <a:documentation>Zoltan Options

Set up some Zoltan options, including which partitioner to use.
Only works if you have the --with-zoltan option in your configure.

Note that Zoltan will become the default (replacing Sam at some point)
and these options are currently here only for development and testing
purposes. They are subject to change and may not be in the final "release".</a:documentation>
      <optional>
        <element name="partitioner">
          <a:documentation>Select which partitioner to use during all but the last adapt iteration.
Graph partitioners available are ParMETIS and Zoltan PHG. The Zoltan
PHG hypergraph partitoner is also available.
Default is the Zoltan PHG graph partitioner.</a:documentation>
          <choice>
            <element name="metis">
              <a:documentation>Use the ParMETIS graph partitioner. ParMETIS setup to match as
closely as possible the setup used previously by Sam.</a:documentation>
              <empty/>
            </element>
            <element name="scotch">
              <a:documentation>Use the PT-Scotch graph partitioner.</a:documentation>
              <empty/>
            </element>
            <element name="zoltan">
              <a:documentation>Use the Zoltan PHG partitioner.</a:documentation>
              <element name="method">
                <a:documentation>Select the partitioning method you would like used by Zoltan PHG.
Currently hypergraph partitioning is the simplest implementation
and can produce non-contiguous partitions for certain problems.</a:documentation>
                <choice>
                  <value>graph</value>
                  <value>hypergraph</value>
                </choice>
              </element>
            </element>
          </choice>
        </element>
      </optional>
      <optional>
        <element name="final_partitioner">
          <a:documentation>Select which partitioner to use after the final adapt iteration.
Graph partitioners available are ParMETIS and Zoltan PHG. The 
Zoltan PHG hypergraph partitoner is also available.
Default is the ParMETIS graph partitioner.</a:documentation>
          <choice>
            <element name="metis">
              <a:documentation>Use the ParMETIS graph partitioner. ParMETIS setup to match as
closely as possible the setup used previously by Sam.</a:documentation>
              <empty/>
            </element>
            <element name="scotch">
              <a:documentation>Use the PT-Scotch graph partitioner.</a:documentation>
              <empty/>
            </element>
            <element name="zoltan">
              <a:documentation>Use the Zoltan PHG partitioner.</a:documentation>
              <element name="method">
                <a:documentation>Select the partitioning method you would like used by Zoltan PHG.
Currently hypergraph partitioning is the simplest implementation
and can produce non-contiguous partitions for certain problems.</a:documentation>
                <choice>
                  <value>graph</value>
                  <value>hypergraph</value>
                </choice>
              </element>
            </element>
          </choice>
        </element>
      </optional>
      <optional>
        <element name="element_quality_cutoff">
          <a:documentation>Element quality cut off. 
Elements with a quality greater than this will be liable to be
on the parition boundary. Below this, they will be free to be adapted
and improved. Range is 0 to 1, with default 0.6
This should be set to the same value as used for the quality option
in libmba2d or libmba3d</a:documentation>
          <ref name="real"/>
        </element>
      </optional>
      <optional>
        <element name="load_imbalance_tolerance">
          <a:documentation>Load imbalance tolerance.
The amount of load imbalance the partitioning algorithm should deem acceptable.
The imbalance is computed as the maximum load divided by the average load.
A value for load_imbalance_tol of 1.2 indicates that 20% imbalance is okay.
A high value for this parameter (~1.5) could see Zoltan produce poorer partitions
but be able to move the partition boundaries easier to allow adaption. For some 
problems where the partitioner creates empty partitions lowering this (~1.075) will
force Zoltan to create more evenly balanced partitions (no empty ones) but may
require more adapt iterations to produce a fully adapted final mesh.</a:documentation>
          <ref name="real"/>
        </element>
      </optional>
      <optional>
        <element name="additional_adapt_iterations">
          <a:documentation>Additional adapt iterations.
Zoltan returns the minimum element quality to adaptivity. By setting additional adapt
iterations to a value greater than zero we allow Zoltan to do adapt_iterations plus
additional_adapt_iterations calls to adaptivity. Additional calls over adapt iterations
are only allowed if Zoltan returns a minimum element quality below the element quality
cut off. Default is 0. </a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <optional>
            <element name="field_weighted_partitions">
              <element name="scalar_field">
                <a:documentation>Field weighted partitions: turning on this option allows one to 
weight mesh partitions, based upon a prescribed scalar field. 
Note that the field should have a minimum value of 0 and a maximum
value of 1 (no normalisation is done within the code).</a:documentation>
                <attribute name="rank">
                  <value>0</value>
                </attribute>
                <attribute name="name">
                  <value>FieldWeightedPartitionValues</value>
                </attribute>
                <choice>
                  <element name="prescribed">
                    <ref name="coordinate_mesh_choice"/>
                    <ref name="prescribed_scalar_field"/>
                  </element>
                  <element name="diagnostic">
                    <ref name="coordinate_mesh_choice"/>
                    <ref name="diagnostic_scalar_field"/>
                  </element>
                </choice>
              </element>
            </element>
          </optional>
          <optional>
            <element name="zoltan_debug">
              <a:documentation>Zoltan Debugging

Turn on more verbose output for use when debugging Zoltan.</a:documentation>
          <optional>
            <element name="graph_checking">
              <a:documentation>Turn on graph checking.
When using ParMETIS or PT-Scotch options for turning on
graph checking are provided by Zoltan.
1 - on process checking,
2 - full checking (very slow)</a:documentation>
              <choice>
                <value>1</value>
                <value>2</value>
              </choice>
            </element>
          </optional>
          <optional>
            <element name="dump_edge_counts">
              <a:documentation>Print out a dump file of the edge counts.
Edge counts for each owned node are calculated in zoltan_cb_get_num_edges.
This option dumps the edge count for each owned node.
Dump is to the current directory, in a file called edge_counts_*.dat
One dump file is created for each rank.
Will get overwritten at each adapt.</a:documentation>
              <empty/>
            </element>
          </optional>
          <optional>
            <element name="dump_edge_weights">
              <a:documentation>Print out a dump file of the edge weights.
Edge weights are calculated for each edge in zoltan_cb_get_edge_list.
Permits a visualisation of how the edge weights are distributed.
Dump is to the current directory, in a file called edge_weights_*.dat
One dump file is created for each rank.
Will get overwritten at each adapt.</a:documentation>
              <empty/>
            </element>
          </optional>
          <optional>
            <element name="dump_node_sizes">
              <a:documentation>Print out a dump file of node sizes.
Zoltan needs to be told how much data is associated with each node when
doing phase one migration.
Here we dump the size calculated by zoltan_cb_pack_node_sizes for each
owned node.
Dump is to the current directory, in a file called node_sizes_*.dat
One dump file is created for each rank.</a:documentation>
              <empty/>
            </element>
          </optional>
          <optional>
            <element name="dump_halo_node_sizes">
              <a:documentation>Print out a dump file of halo node sizes.
Zoltan needs to be told how much data is associated with each halo node when
doing phase two migration.
Here we dump the size calculated by zoltan_cb_pack_halo_node_sizes for each
owned node.
Dump is to the current directory, in a file called halo_node_sizes_*.dat
One dump file is created for each rank.</a:documentation>
              <empty/>
            </element>
          </optional>
          <optional>
            <element name="dump_field_sizes">
              <a:documentation>Print out a dump file of field sizes.
Zoltan needs to be told how much data is associated with the fields for each 
element when we're transfering fields.
Here we dump the size calculated by zoltan_cb_pack_field_sizes for each
owned node.
Dump is to the current directory, in a file called field_sizes_*.dat
One dump file is created for each rank.</a:documentation>
              <empty/>
            </element>
          </optional>
        </element>
      </optional>
    </element>
  </define>
  <define name="adaptivity_library">
    <element name="adaptivity_library">
      <a:documentation>Select the adaptivity library used by hr-adaptivity. If disabled,
the defaults are:
  In 3D: libadaptivity
  In 2D: libmba2d
  In 1D: adaptivity_1d</a:documentation>
      <choice>
        <element name="libadaptivity">
          <a:documentation>libadaptivity. 3D, parallelised.</a:documentation>
          <optional>
            <element name="sweeps">
              <a:documentation>The number of adaptivity sweeps. Default value: 10</a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <optional>
            <element name="disable_edge_split">
              <a:documentation>Enable this option to turn off edge splitting</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <optional>
            <element name="disable_edge_collapse">
              <a:documentation>Enable this option to turn off edge collapsing</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <optional>
            <element name="disable_edge_swap">
              <a:documentation>Enable this option to turn off edge/face, face/edge and
edge/edge swapping</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <optional>
            <element name="disable_node_movement">
              <a:documentation>Enable this option to turn off node movement, and use
h-adaptivity only.</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <optional>
            <element name="write_adapted_quality">
              <a:documentation>Writes vtus containing the Pain 2001 P0 element functionals
of the adapted meshes.</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <ref name="comment"/>
        </element>
        <element name="libmba2d">
          <a:documentation>libmba2d. 2D. A testing parallel implementation is available.</a:documentation>
          <optional>
            <element name="quality">
              <a:documentation>Desired output mesh quality, 0 &lt;= quality &lt;= 1.
Default value 0.6.</a:documentation>
              <ref name="real"/>
            </element>
          </optional>
          <ref name="comment"/>
        </element>
        <element name="adaptivity_1d">
          <a:documentation>Re-uses 1D adaptivity code from 2+1D adaptivity. 1D, serial only.</a:documentation>
          <ref name="comment"/>
        </element>
        <element name="libmba3d">
          <a:documentation>libmba3d. 3D, serial only.</a:documentation>
          <optional>
            <element name="quality">
              <a:documentation>Desired output mesh quality, 0 &lt;= quality &lt;= 1.
Default value 0.6.</a:documentation>
              <ref name="real"/>
            </element>
          </optional>
          <optional>
            <element name="max_optimisations">
              <a:documentation>Maximum number of mesh optimisations. Default value 10^5.</a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <ref name="comment"/>
        </element>
      </choice>
    </element>
  </define>
  <define name="adapt_iterations">
    <element name="adapt_iterations">
      <a:documentation>Number of times the adaptivity library is called. In parallel elements
near the local domain boundary are locked during the mesh adaptation. The mesh
is then redistributed in such a way that these locked regions are moved into the
interior of local domains and adaptivity is called again to adapt these not-yet-adapted
regions. By default, in parallel, the number of times the adaptivity library is called
in this way is three. If a relatively small mesh is distributed among a large number
of processors, a large proportion of the mesh is locked during adaptivity and more
iterations may be necessary.</a:documentation>
      <ref name="integer"/>
    </element>
  </define>
  <define name="hr_adaptivity_debug">
    <element name="debug">
      <a:documentation>hr adptivity debugging options</a:documentation>
      <optional>
        <element name="write_metric_stages">
          <a:documentation>Write out error metric at each stage of the processing
pipeline. This can be very useful in diagnosing why
adaptivity is doing something you don't expect.</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <optional>
            <element name="write_adapted_mesh">
              <a:documentation>Write out the Coordinate field to a mesh for every
state adapt. In parallel, mesh and .halo files
will be written for every parallel adapt iteration.</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
      <optional>
        <element name="write_adapted_state">
          <a:documentation>Write out the system state to a vtu adapt every state adapt.
In parallel, a vtu will be written for every parallel
adapt iteration.</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
      <optional>
        <element name="write_periodic_adapted_mesh">
          <a:documentation>Write periodic meshes and surface IDs to vtus at each stage of the processing
pipeline. This can be very useful in diagnosing why
adaptivity is doing something you don't expect.</a:documentation>
          <ref name="comment"/>
        </element>
      </optional>
      <optional>
        <element name="checkpoint">
          <a:documentation>Checkpoint the simulation after every adapt. In parallel, a
checkpoint will be written &lt;b&gt;only&lt;/b&gt; after the final adapt
iteration. Checkpoints are postfixed with "adapt_checkpoint".</a:documentation>
          <optional>
            <element name="max_checkpoint_count">
              <a:documentation>Number of checkpoints to write before overwriting existing
checkpoints.</a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <ref name="comment"/>
        </element>
      </optional>
      <ref name="comment"/>
    </element>
  </define>
  <define name="prescribed_adaptivity">
    <element name="prescribed_adaptivity">
      <a:documentation>Mesh adaptivity, with prescribed adapt interval and target meshes.
&lt;b&gt;Serial only&lt;/b&gt;.</a:documentation>
      <element name="adapt_interval">
        <a:documentation>Options relating the the frequency of mesh adaptivity</a:documentation>
        <element name="python">
          <a:documentation>Python code defining whether to adapt the mesh, evaluated at the
end of each timestep. Return non-zero to signal a mesh adapt, and
zero otherwise. Functions should be of the form:

 def val(t):
   # Function code
   return # Return value

The return value must be an integer.</a:documentation>
          <ref name="python_code"/>
        </element>
        <ref name="comment"/>
      </element>
      <element name="mesh">
        <a:documentation>Options relating to the target meshes</a:documentation>
        <element name="name">
          <a:documentation>The target mesh. If not reading from file, this must be a mesh
specified under /geometry.</a:documentation>
          <element name="python">
            <a:documentation>Python code defining the target mesh. Functions should be of
the form:

 def val(t):
   # Function code
   return # Return value

The return value must be a string.</a:documentation>
            <ref name="python_code"/>
          </element>
          <ref name="comment"/>
        </element>
        <optional>
          <element name="from_file">
            <a:documentation>Read the mesh from file, rather than extracting it from the
system state.</a:documentation>
            <element name="format">
              <a:documentation>GMSH mesh format</a:documentation>
              <attribute name="name">
                <value>gmsh</value>
              </attribute>
              <ref name="comment"/>
            </element>
            <ref name="comment"/>
          </element>
        </optional>
        <ref name="comment"/>
      </element>
      <ref name="comment"/>
    </element>
  </define>
  <define name="consistent_interpolation">
    <element name="consistent_interpolation">
      <a:documentation>Basis function interpolation.
The standard algorithm. It is quick
and bounded, but non-conservative and dissipative.
All other algorithms require construction of a supermesh.</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="pseudo_consistent_interpolation">
    <element name="pseudo_consistent_interpolation">
      <a:documentation>Basis function pseudo-interpolation, with averaging for nodes on
element boundaries. This can accept a discontinuous input, but always
gives a continuous output. It is strong recommended that you &lt;b&gt;use
interpolation_galerkin&lt;/b&gt; instead of this interpolation method.

The distance in ideal space from the boundary where averaging is
applied is currently hard coded to 1.0e3 * epsilon(0.0).</a:documentation>
      <ref name="comment"/>
    </element>
  </define>
  <define name="grandy_interpolation">
    <element name="grandy_interpolation">
      <a:documentation>Grandy interpolation. Conservative, but highly diffusive.
See doi:10.1006/jcph.1998.6125 .</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="interpolation_algorithm_disabled">
    <element name="no_interpolation">
      <a:documentation>Disable interpolation</a:documentation>
      <ref name="comment"/>
    </element>
  </define>
  <define name="interpolation_algorithm_scalar">
    <choice>
      <ref name="consistent_interpolation"/>
      <ref name="pseudo_consistent_interpolation"/>
      <element name="galerkin_projection">
        <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
        <ref name="galerkin_projection_scalar"/>
      </element>
      <ref name="grandy_interpolation"/>
    </choice>
  </define>
  <define name="interpolation_algorithm_scalar_full">
    <ref name="interpolation_algorithm_scalar"/>
  </define>
  <define name="interpolation_algorithm_scalar_full" combine="choice">
    <ref name="interpolation_algorithm_disabled"/>
  </define>
  <define name="interpolation_algorithm_vector_full">
    <ref name="interpolation_algorithm_vector"/>
  </define>
  <define name="interpolation_algorithm_vector_full" combine="choice">
    <ref name="interpolation_algorithm_disabled"/>
  </define>
  <define name="interpolation_algorithm_vector">
    <choice>
      <ref name="consistent_interpolation"/>
      <ref name="pseudo_consistent_interpolation"/>
      <element name="galerkin_projection">
        <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
        <ref name="galerkin_projection_vector"/>
      </element>
      <ref name="grandy_interpolation"/>
      <element name="geostrophic_interpolation">
        <a:documentation>Helmholtz decomposed projection of the Coriolis acceleration. Suitable
only for Velocity fields. This interpolation happens in three stages:

  1. Computation of Coriolis and its Helmholtz decomposition
  2. Interpolation of the Helmholtz decomposition
  3. Formation of Coriolis from the decomposition and inversion for velocity

Notes for balance preserving interpolants:

The spatial discretisation options for the conservative potential
must match those used for Pressure.

With weak boundary conditions for the conservative potential, if
no-normal-flow is satisfied on the boundary this must be preserved by
the interpolation. For 2D domains this can be achieved by using
consistent interpolation for the conservative potential or, for more
general interpolants, by performing a further decomposition of the
conservative potential (see
geostrophic_interpolation/conservative_potential/decompose).

For shallow-water modelling the interpolants for layer thickness and
the conservative potential must be identical and degree one
homogenenous (see
geostrophic_interpolation/conservative_potential/project_pressure/scale_factor).</a:documentation>
        <element name="coriolis">
          <a:documentation>Options relating to the Coriolis acceleration</a:documentation>
          <optional>
            <choice>
              <element name="mesh">
                <a:documentation>The mesh used for the Coriolis acceleration. Defaults to the
Velocity mesh if not supplied.</a:documentation>
                <attribute name="name">
                  <value>VelocityMesh</value>
                </attribute>
              </element>
              <element name="mesh">
                <a:documentation>The mesh used for the Coriolis acceleration. Defaults to the
Velocity mesh if not supplied.</a:documentation>
                <attribute name="name">
                  <value>PressureMesh</value>
                </attribute>
              </element>
              <element name="mesh">
                <a:documentation>The mesh used for the Coriolis acceleration. Defaults to the
Velocity mesh if not supplied.</a:documentation>
                <attribute name="name">
                  <value>CoordinateMesh</value>
                </attribute>
              </element>
              <element name="mesh">
                <a:documentation>The mesh used for the Coriolis acceleration. Defaults to the
Velocity mesh if not supplied.</a:documentation>
                <attribute name="name">
                  <data type="string" datatypeLibrary=""/>
                </attribute>
              </element>
            </choice>
          </optional>
          <element name="velocity_to_coriolis">
            <a:documentation>Options relating to the diagnostic solve for the Coriolis
acceleration from Velocity on the donor mesh.</a:documentation>
            <optional>
              <ref name="galerkin_projection_mass_options"/>
            </optional>
            <optional>
              <element name="lump_rhs">
                <a:documentation>Lump the RHS term. Requires Velocity and the Coriolis 
acceleration to be on the same mesh.</a:documentation>
                <ref name="comment"/>
              </element>
            </optional>
            <ref name="comment"/>
          </element>
          <element name="coriolis_to_velocity">
            <a:documentation>Options relating to the diagnostic solve for Velocity from
the Coriolis acceleration on the target mesh.</a:documentation>
            <optional>
              <ref name="galerkin_projection_mass_options"/>
            </optional>
            <optional>
              <element name="lump_rhs">
                <a:documentation>Lump the RHS term. Requires Velocity and the Coriolis 
acceleration to be on the same mesh.</a:documentation>
                <ref name="comment"/>
              </element>
            </optional>
            <ref name="comment"/>
          </element>
          <ref name="comment"/>
        </element>
        <element name="conservative_potential">
          <a:documentation>Options relating to the conservative potential component of the
Helmholtz decomposition</a:documentation>
          <choice>
            <element name="mesh">
              <a:documentation>The mesh used for the conservative potential. Note that this is
computed using the same method as the pressure projection, and
hence LBB constraints apply.</a:documentation>
              <attribute name="name">
                <value>PressureMesh</value>
              </attribute>
            </element>
            <element name="mesh">
              <a:documentation>The mesh used for the conservative potential. Note that this is
computed using the same method as the pressure projection, and
hence LBB constraints apply.</a:documentation>
              <attribute name="name">
                <value>VelocityMesh</value>
              </attribute>
            </element>
            <element name="mesh">
              <a:documentation>The mesh used for the conservative potential. Note that this is
computed using the same method as the pressure projection, and
hence LBB constraints apply.</a:documentation>
              <attribute name="name">
                <value>CoordinateMesh</value>
              </attribute>
            </element>
            <element name="mesh">
              <a:documentation>The mesh used for the conservative potential. Note that this is
computed using the same method as the pressure projection, and
hence LBB constraints apply.</a:documentation>
              <attribute name="name">
                <data type="string" datatypeLibrary=""/>
              </attribute>
            </element>
          </choice>
          <element name="spatial_discretisation">
            <a:documentation>Spatial discretisation options</a:documentation>
            <element name="mass">
              <a:documentation>Options relating to the mass matrix</a:documentation>
              <optional>
                <element name="lump_mass">
                  <a:documentation>Lump the mass matrix. Required for continuous fields.</a:documentation>
                  <ref name="comment"/>
                </element>
              </optional>
            </element>
            <element name="continuous_galerkin">
              <a:documentation>Use a continuous Galerkin discretisation</a:documentation>
              <optional>
                <element name="integrate_divergence_by_parts">
                  <a:documentation>Integrate the divergence operator by parts</a:documentation>
                  <ref name="comment"/>
                </element>
              </optional>
              <optional>
                <element name="remove_stabilisation_term">
                  <a:documentation>Remove the stabilisation term from the projection operator.

Automatic when not using P1P1.</a:documentation>
                  <ref name="comment"/>
                </element>
              </optional>
              <ref name="comment"/>
            </element>
            <ref name="comment"/>
          </element>
          <optional>
            <element name="reference_node">
              <a:documentation>Reference node, at which the solution value is pinned to zero</a:documentation>
              <ref name="integer"/>
            </element>
          </optional>
          <element name="solver">
            <a:documentation>Solver options for the conservative potential calculation</a:documentation>
            <ref name="linear_solver_options_sym"/>
          </element>
          <choice>
            <element name="galerkin_projection">
              <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
              <ref name="galerkin_projection_honour_strong_bcs"/>
              <ref name="continuous_projection"/>
              <optional>
                <ref name="supermesh_conservation"/>
              </optional>
              <ref name="comment"/>
            </element>
            <ref name="consistent_interpolation"/>
            <ref name="grandy_interpolation"/>
          </choice>
          <optional>
            <choice>
              <element name="project_pressure">
                <a:documentation>Supply a Pressure field. This enables better initial guesses for
the decomposition solvers, and also allows decomposed interpolants
for Pressure (see
geostrophic_interpolation/conservative_potential/decompose and
geostrophic_interpolation/conservative_potential/interpolate_boundary).</a:documentation>
                <attribute name="name">
                  <value>Pressure</value>
                </attribute>
                <optional>
                  <ref name="geostrophic_interpolation_project_pressure_scale_factor"/>
                </optional>
                <ref name="comment"/>
              </element>
              <element name="project_pressure">
                <a:documentation>Supply a Pressure field. This enables better initial guesses for
the decomposition solvers, and also allows decomposed interpolants
for Pressure (see
geostrophic_interpolation/conservative_potential/decompose and
geostrophic_interpolation/conservative_potential/interpolate_boundary).</a:documentation>
                <attribute name="name">
                  <value>LayerThickness</value>
                </attribute>
                <ref name="geostrophic_interpolation_project_pressure_scale_factor"/>
                <ref name="comment"/>
              </element>
              <element name="project_pressure">
                <a:documentation>Supply a Pressure field. This enables better initial guesses for
the decomposition solvers, and also allows decomposed interpolants
for Pressure (see
geostrophic_interpolation/conservative_potential/decompose and
geostrophic_interpolation/conservative_potential/interpolate_boundary).</a:documentation>
                <attribute name="name">
                  <data type="string"/>
                </attribute>
                <optional>
                  <ref name="geostrophic_interpolation_project_pressure_scale_factor"/>
                </optional>
                <ref name="comment"/>
              </element>
            </choice>
          </optional>
          <optional>
            <choice>
              <element name="decompose">
                <a:documentation>Decompose the conservative potential into a component constant
on the boundary, and a residual.

If interpolating Pressure, a similar decomposition is applied
to the Pressure projection.

This requires the domain to be 2D and simply connected.</a:documentation>
                <choice>
                  <element name="l2_minimised_residual">
                    <a:documentation>Choose a boundary value that minimises the l2 norm of the
residual</a:documentation>
                    <ref name="comment"/>
                  </element>
                  <element name="boundary_mean">
                    <a:documentation>Use the mean boundary value</a:documentation>
                    <ref name="comment"/>
                  </element>
                </choice>
                <element name="solver">
                  <a:documentation>Solver options for the decomposition</a:documentation>
                  <ref name="linear_solver_options_sym"/>
                </element>
                <ref name="comment"/>
              </element>
              <element name="interpolate_boundary">
                <a:documentation>Interpolate the boundary values using consistent interpolation and
use these as a strong Dirichlet boundary condition on the
conservative potential.

If interpolating Pressure, a similar boundary condition is applied
to the Pressure projection.</a:documentation>
                <ref name="comment"/>
              </element>
            </choice>
          </optional>
          <ref name="comment"/>
        </element>
        <element name="residual">
          <a:documentation>Options relating to the non-conservative residual component of the
Helmholz decomposition</a:documentation>
          <choice>
            <element name="galerkin_projection">
              <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
              <ref name="continuous_discontinuous_projection"/>
              <optional>
                <ref name="supermesh_conservation"/>
              </optional>
              <ref name="comment"/>
            </element>
            <ref name="consistent_interpolation"/>
            <ref name="pseudo_consistent_interpolation"/>
            <ref name="grandy_interpolation"/>
          </choice>
          <optional>
            <element name="enforce_solenoidal">
              <a:documentation>Enforce divergence free after the projection</a:documentation>
              <ref name="comment"/>
            </element>
          </optional>
          <ref name="comment"/>
        </element>
        <optional>
          <element name="geopressure">
            <a:documentation>If enabled, preconditions the Helmholtz decomposition by solving
for the conservative potential using a geopressure solver. The
projection equation then becomes:
  M f = M f_* + C \phi + C_{gp} \phi_{gp},
where f_* is the coriolis acceleration, f is divergence free, phi is
the conservative potential, phi_gp is the geopressure conservative
potential and:
  C_{gp,ij}^q = \int_Omega N_j \partial_q M_i,
is the geopressure gradient matrix, where N_i are the velocity shape
functions and M_i the geopressure conservative potential shape
functions.</a:documentation>
            <element name="mesh">
              <a:documentation>The mesh used for the geopressure conservative potential</a:documentation>
              <attribute name="name">
                <data type="string" datatypeLibrary=""/>
              </attribute>
            </element>
            <optional>
              <element name="reference_node">
                <a:documentation>Reference node, at which the solution value is pinned to zero</a:documentation>
                <ref name="integer"/>
              </element>
            </optional>
            <element name="solver">
              <a:documentation>Solver options for the geopressure conservative potential
calculation</a:documentation>
              <ref name="linear_solver_options_sym"/>
            </element>
            <choice>
              <element name="galerkin_projection">
                <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
                <ref name="continuous_projection"/>
                <optional>
                  <ref name="supermesh_conservation"/>
                </optional>
                <ref name="comment"/>
              </element>
              <ref name="consistent_interpolation"/>
              <ref name="pseudo_consistent_interpolation"/>
              <ref name="grandy_interpolation"/>
            </choice>
          </element>
        </optional>
        <optional>
          <element name="vertical_velocity">
            <a:documentation>Options relating to the vertical velocity. Required in 3D.</a:documentation>
            <choice>
              <element name="galerkin_projection">
                <a:documentation>Galerkin projection. By default, conservative, non-dissipative and
non-bounded. The most accurate choice, in the sense of minimising
the L2 norm of the residual</a:documentation>
                <ref name="continuous_discontinuous_projection"/>
                <optional>
                  <ref name="supermesh_conservation"/>
                </optional>
                <ref name="comment"/>
              </element>
              <ref name="consistent_interpolation"/>
              <ref name="pseudo_consistent_interpolation"/>
              <ref name="grandy_interpolation"/>
            </choice>
            <ref name="comment"/>
          </element>
        </optional>
        <optional>
          <element name="debug">
            <a:documentation>Debug options</a:documentation>
            <optional>
              <element name="write_debug_vtus">
                <a:documentation>If enabled, pre and post interpolation decomposition vtus are
written</a:documentation>
                <optional>
                  <element name="max_vtu_count">
                    <a:documentation>Maximum number of debug vtus that will be written before
over-writing existing vtus</a:documentation>
                    <ref name="integer"/>
                  </element>
                </optional>
                <ref name="comment"/>
              </element>
            </optional>
            <ref name="comment"/>
          </element>
        </optional>
        <ref name="comment"/>
      </element>
    </choice>
  </define>
  <define name="geostrophic_interpolation_project_pressure_scale_factor">
    <element name="scale_factor">
      <a:documentation>Scale the pressure field by some factor before interpolation,
and apply the inverse after interpolation. This should be set
if the pressure field is divided by some reference value
e.g., in a shallow water with gravity magnitude g, this should
take the value g. This enables better initial guesses for the
decomposition solvers, and means that non degree one
homonogeneous interpolants can be used for the conservative
potential and pressure, while still being balance preserving.</a:documentation>
      <ref name="real"/>
    </element>
  </define>
  <define name="galerkin_projection_honour_strong_bcs">
    <element name="honour_strong_boundary_conditions">
      <a:documentation>Honour strong Dirichlet boundary conditions in the Galerkin projection</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="galerkin_projection_vector">
    <ref name="continuous_discontinuous_projection"/>
    <optional>
      <ref name="supermesh_free"/>
    </optional>
    <optional>
      <ref name="supermesh_conservation"/>
    </optional>
    <optional>
      <ref name="galerkin_projection_honour_strong_bcs"/>
    </optional>
  </define>
  <define name="galerkin_projection_scalar">
    <ref name="continuous_discontinuous_projection"/>
    <optional>
      <ref name="supermesh_free"/>
    </optional>
    <optional>
      <ref name="supermesh_conservation"/>
    </optional>
    <optional>
      <ref name="galerkin_projection_honour_strong_bcs"/>
    </optional>
  </define>
  <define name="continuous_projection">
    <element name="continuous">
      <a:documentation>Continuous field Galerkin projection.
If the field you are interpolating is continuous, then
a linear solver is required to invert the mass matrix.</a:documentation>
      <optional>
        <element name="bounded">
          <a:documentation>Use a bounded Galerkin projection. Conservative, bounded in the
limit, and minimally dissipative. This algorithm starts with the
Galerkin projection and dissipates it until it achieves
boundedness.
If it does not converge, it may not be exactly bounded.
Note well: this only works for linear fields.</a:documentation>
          <attribute name="name">
            <value>Diffuse</value>
          </attribute>
          <element name="boundedness_iterations">
            <a:documentation>The number of dissipation iterations attempted to bound the
Galerkin projection.</a:documentation>
            <ref name="integer"/>
            <optional>
              <element name="tolerance">
                <a:documentation>Specify the tolerance to which boundedness is to be tested during the iterations.
Defaults to computer precision if unspecified.</a:documentation>
                <ref name="real"/>
              </element>
            </optional>
          </element>
          <optional>
            <element name="bounds">
              <a:documentation>If the bounds on this field are known then they can be set here.
These can either further constrain the limits worked out by the
lumped version of the projection (i.e. to make sure that errors 
don't accumulate with succesive interpolations) or if apply_globally
is set they are just made to be bounded within the bounds globally
(i.e. anything between those bounds is not smoothed).</a:documentation>
              <optional>
                <element name="upper_bound">
                  <ref name="real"/>
                  <optional>
                    <element name="apply_globally">
                      <a:documentation>If this is set the upper_bound is used everywhere.
If left unset the upper_bound is only used to constrain
the smoothed bounds calculated by the code</a:documentation>
                      <empty/>
                    </element>
                  </optional>
                  <optional>
                    <element name="coupled">
                      <a:documentation>This field is to be considered as being coupled to another field
such that the sum of the two fields is constrained to be less than
the upper_bound specified above.

The relationships between fields are worked out according to their
priority ordering.

This method is akin to the coupled_cv advection method.</a:documentation>
                      <empty/>
                    </element>
                  </optional>
                </element>
              </optional>
              <optional>
                <element name="lower_bound">
                  <ref name="real"/>
                  <optional>
                    <element name="apply_globally">
                      <a:documentation>If this is set the upper_bound is used everywhere.
If left unset the upper_bound is only used to constrain
the smoothed bounds calculated by the code</a:documentation>
                      <empty/>
                    </element>
                  </optional>
                </element>
              </optional>
            </element>
          </optional>
          <optional>
            <element name="repair_deviations">
              <a:documentation>If, after performing all the boundedness_iterations, the field
is still not bounded then perform surgery to redistribute the
deviations to nodes that have less than their bounds.</a:documentation>
              <optional>
                <element name="tolerance">
                  <a:documentation>Specify the tolerance to which boundedness is to be tested during the repair.
Defaults to computer precision if unspecified.</a:documentation>
                  <ref name="real"/>
                </element>
              </optional>
            </element>
          </optional>
        </element>
      </optional>
      <choice>
        <element name="solver">
          <a:documentation>Solver options for the linear solve.
This method requires the inversion of a mass matrix. Note that
conservation properties are affected by the tolerance of the
linear solve.</a:documentation>
          <ref name="linear_solver_options_sym"/>
        </element>
        <element name="lump_mass_matrix">
          <a:documentation>Lump the mass matrix on the left hand side of the galerkin projection.
Hence solver options aren't necessary.

This is much more diffusive than a non-lumped Galerkin projection
for only a minimal saving in computational cost.</a:documentation>
          <empty/>
        </element>
      </choice>
    </element>
  </define>
  <define name="continuous_discontinuous_projection">
    <choice>
      <ref name="continuous_projection"/>
      <element name="discontinuous">
        <a:documentation>Discontinuous field Galerkin projection.
In this case, no linear solver is required to invert the mass matrix.</a:documentation>
        <empty/>
      </element>
    </choice>
  </define>
  <define name="supermesh_free">
    <element name="supermesh_free">
      <a:documentation>Enables a supermesh free Galerkin projection. Uses incomplete
quadrature, and hence is not conservative.</a:documentation>
      <empty/>
    </element>
  </define>
  <define name="supermesh_conservation">
    <element name="supermesh_conservation">
      <a:documentation>Options for checking the supermesh conservation properties</a:documentation>
      <optional>
        <element name="tolerance">
          <a:documentation>Specify the fraction of the original elemental area/volume
to be used to check the conservation of the supermesh.

Since all fields are supermeshed together the minimum tolerance
specified over all fields will be used.

Defaults to 0.001 if unspecified.
i.e. 0.1% of the area/volume of an element in the new mesh may
be lost without warning or attempts to fix (if compiled with cgal)
during the construction of the supermesh between the old
and new meshes.</a:documentation>
          <ref name="real"/>
        </element>
      </optional>
      <optional>
        <element name="print_field_integral">
          <a:documentation>Compute the field integral after the interpolation and print the relative
mass loss to the logfile (level 2 verbosity).

Note this is a post interpolation step and offers no chance of
fixing the conservation error (unlike the tolerance above if compiled
with cgal)</a:documentation>
          <element name="tolerance">
            <a:documentation>Relative tolerance with which to test the conservation of the field
integral.  If the conservation fails this tolerance a warning is issued
(level 0 verbosity) and vtus containing the field are output.</a:documentation>
            <ref name="real"/>
          </element>
        </element>
      </optional>
    </element>
  </define>
  <define name="mesh_adaptivity_options">
    <element name="mesh_adaptivity">
      <optional>
        <element name="mesh_movement">
          <a:documentation>Options involving mesh movement (Lagrangian, ALE methods)
 Allow a moving mesh.
 Assigns memory for grid velocities
 Amends previous timestep`s mass matrix</a:documentation>
          <choice>
            <element name="free_surface">
              <a:documentation>enable movement of mesh with the free surface</a:documentation>
              <choice>
                <element name="move_surface_nodes">
                  <a:documentation>Only move the nodes on the free surface using
the surface height calculated at it.</a:documentation>
                  <empty/>
                </element>
                <element name="move_whole_mesh">
                  <a:documentation>Move the whole mesh according to the free surface
height, scaled linearly by the depth from the surface.

Requires the specification of ocean_boundaries under
geometry.</a:documentation>
                  <empty/>
                </element>
              </choice>
              <optional>
                <element name="wetting_and_drying">
                  <a:documentation>Activates wetting and drying. Note: Works only with theta=1.0 and relaxation=1.0 under temporal discretisation</a:documentation>
                  <element name="d0">
                    <a:documentation>Specifies the d0 value which is the waterlevel kept in dry areas.</a:documentation>
                    <ref name="real"/>
                  </element>
                  <optional>
                    <element name="dry_absorption">
                      <a:documentation>Specifies the amount of absorption in dry areas. If a pressure corrected absorption term is desired, please add a pressure corrected absorption under Velocity (of magnitude 0).
Note: If you double d0, this value has to be doubled as well to achieve the same amount of absorption.</a:documentation>
                      <ref name="real_dim_vector"/>
                    </element>
                  </optional>
                  <optional>
                    <element name="conserve_geometric_volume">
                      <a:documentation>With wetting and drying the free surface is the maximum of two functions in the pressure finite element space. The result is in general not a function of the finite element space and 
can therefore not be represented exactly on the pressure mesh.
This option enables geometrical volume conservation by evaluating the maximum operator only at the nodal positions (instead of at each quadrature point),
on the cost of a worse internal representation of the wetting and drying interface.</a:documentation>
                      <empty/>
                    </element>
                  </optional>
                </element>
              </optional>
            </element>
            <element name="imposed_grid_velocity">
              <a:documentation>Enable movement of mesh by an imposed Grid Velocity.
Requires a prescribed GridVelocity field (see below).</a:documentation>
              <empty/>
            </element>
            <element name="pseudo_lagrangian">
              <a:documentation>Enable movement of mesh by the Velocity.
Note that this is only pseudo-lagrangian as the
Velocity and GridVelocity only match at the beginning of
the timestep.  Therefore the advection terms are still
present and evaluated.</a:documentation>
              <optional>
                <element name="velocity_material_phase">
                  <a:documentation>Specify the material phase from which to extract the Velocity
field.  Defaults to state(1) if unspecified.  Note that this
doesn't necessarily correspond to the first material_phase
in a flml file!</a:documentation>
                  <attribute name="material_phase_name">
                    <data type="string"/>
                  </attribute>
                  <empty/>
                </element>
              </optional>
            </element>
            <element name="explicit_ale">
              <a:documentation>enable full ale movement of mesh</a:documentation>
              <element name="number_of_linesearch_pts">
                <ref name="integer"/>
              </element>
              <element name="maximum_iterations">
                <ref name="integer"/>
              </element>
              <element name="max_elements_second_level">
                <ref name="integer"/>
              </element>
              <element name="functional1_weight">
                <ref name="real"/>
              </element>
              <element name="functional2_weight">
                <ref name="real"/>
              </element>
              <element name="functional3_weight">
                <ref name="real"/>
              </element>
              <element name="functional4_weight">
                <ref name="real"/>
              </element>
              <element name="functional5_weight">
                <ref name="real"/>
              </element>
              <element name="minimum_val_functional_change">
                <ref name="real"/>
              </element>
              <element name="minimum_val_functional">
                <ref name="real"/>
              </element>
              <element name="coarse_tolerance">
                <ref name="real"/>
              </element>
              <element name="fine_tolerance">
                <ref name="real"/>
              </element>
              <element name="gradient_dx">
                <ref name="real"/>
              </element>
              <element name="gradient_dy">
                <ref name="real"/>
              </element>
              <element name="gradient_dz">
                <ref name="real"/>
              </element>
              <optional>
                <element name="move_nodes_in_x">
                  <empty/>
                </element>
              </optional>
              <optional>
                <element name="move_nodes_in_y">
                  <empty/>
                </element>
              </optional>
              <optional>
                <element name="move_nodes_in_z">
                  <empty/>
                </element>
              </optional>
            </element>
            <element name="vertical_ale">
              <a:documentation>enable vertical movement of mesh (TBD)</a:documentation>
              <element name="physical_functionals">
                <a:documentation>Functionals</a:documentation>
                <choice>
                  <element name="minimise_relative_velocity_dot_grad_density">
                    <a:documentation>move the nodes along an isosurface
Please specify a scalar field</a:documentation>
                    <attribute name="name">
                      <data type="string"/>
                    </attribute>
                  </element>
                  <element name="use_hessian_density">
                    <a:documentation>Lock a node to a high curvature region, 
Please specify a scalar field</a:documentation>
                    <attribute name="name">
                      <data type="string"/>
                    </attribute>
                  </element>
                </choice>
              </element>
              <optional>
                <element name="mesh_quality_terms">
                  <a:documentation>Mesh Quality terms</a:documentation>
                  <optional>
                    <element name="spring_term">
                      <a:documentation>Spring term, default value is 1.0</a:documentation>
                      <ref name="real"/>
                    </element>
                  </optional>
                  <optional>
                    <element name="exponential_term">
                      <a:documentation>Exponential term, default value is 1.0</a:documentation>
                      <ref name="real"/>
                    </element>
                  </optional>
                </element>
              </optional>
              <optional>
                <element name="block_nodes_in_x">
                  <empty/>
                </element>
              </optional>
              <optional>
                <element name="block_nodes_in_y">
                  <empty/>
                </element>
              </optional>
              <optional>
                <element name="block_nodes_in_z">
                  <empty/>
                </element>
              </optional>
            </element>
          </choice>
          <element name="vector_field">
            <a:documentation>The velocity of the mesh.</a:documentation>
            <attribute name="name">
              <value>GridVelocity</value>
            </attribute>
            <attribute name="rank">
              <value>1</value>
            </attribute>
            <choice>
              <element name="diagnostic">
                <ref name="internal_algorithm"/>
                <element name="mesh">
                  <attribute name="name">
                    <value>CoordinateMesh</value>
                  </attribute>
                </element>
                <ref name="diagnostic_vector_field"/>
              </element>
              <element name="prescribed">
                <element name="mesh">
                  <attribute name="name">
                    <value>CoordinateMesh</value>
                  </attribute>
                </element>
                <ref name="prescribed_vector_field_no_adapt"/>
              </element>
              <element name="aliased">
                <ref name="generic_aliased_field"/>
              </element>
            </choice>
          </element>
        </element>
      </optional>
      <optional>
        <choice>
          <ref name="hr_adaptivity"/>
          <ref name="prescribed_adaptivity"/>
        </choice>
      </optional>
    </element>
  </define>
  <define name="gradation_options_full">
    <ref name="disable_gradation"/>
  </define>
  <define name="gradation_options_full" combine="choice">
    <ref name="gradation_options"/>
  </define>
  <define name="gradation_options">
    <choice>
      <element name="enable_gradation">
        <a:documentation>Gradation constrains the jump
in desired edge lengths along an edge, i.e.
it controls how fast the mesh size may change.</a:documentation>
        <optional>
          <element name="gradation_parameter">
            <a:documentation>The gradation parameter. Must be a real &gt;= 1.0.

The gradation parameter constrains the jump
in desired edge lengths along an edge, i.e.
it controls how fast the mesh size may change.
A constant of 1.0 enforces a mesh of constant
edge length everywhere. A value of 2.0 would
allow the element size to double from element
to element. The default value is 1.5.</a:documentation>
            <ref name="real"/>
          </element>
        </optional>
      </element>
      <element name="anisotropic_gradation">
        <a:documentation>Anisotropic gradation algorithm, allowing for
anisotropic bounds on the gradient of the sizing
function.</a:documentation>
        <element name="tensor_field">
          <a:documentation>Gamma is the tensor field that contains
the bounds on the edge length specified by the error metric.</a:documentation>
          <attribute name="name">
            <value>Gamma</value>
          </attribute>
          <element name="anisotropic_symmetric">
            <ref name="input_choice_real_dim_symmetric_tensor"/>
          </element>
        </element>
      </element>
    </choice>
  </define>
  <define name="disable_gradation">
    <element name="disable_gradation">
      <a:documentation>Gradation constrains the jump
in desired edge lengths along an edge, i.e.
it controls how fast the mesh size may change.</a:documentation>
      <empty/>
    </element>
  </define>
</grammar>
